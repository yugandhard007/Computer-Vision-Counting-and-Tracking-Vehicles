{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"gj7nWw_-50ae","executionInfo":{"status":"ok","timestamp":1702104556547,"user_tz":-330,"elapsed":16,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}}},"outputs":[],"source":["# !nvidia-smi"]},{"cell_type":"code","source":["import os\n","HOME = os.getcwd()\n","print(HOME)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORz9r6Il6CWH","executionInfo":{"status":"ok","timestamp":1702104556548,"user_tz":-330,"elapsed":15,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}},"outputId":"17456493-ea62-4d60-8b84-faa71209274e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uQ8Hn8_u6CYq","executionInfo":{"status":"ok","timestamp":1702104556549,"user_tz":-330,"elapsed":13,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install ultralytics\n","\n","from IPython import display\n","display.clear_output()\n","\n","import ultralytics\n","ultralytics.checks()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CceQkm6C6CbS","executionInfo":{"status":"ok","timestamp":1702104579976,"user_tz":-330,"elapsed":23439,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}},"outputId":"66848057-4dba-4142-bb90-b391cc23746c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.0.225 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CPU (Intel Xeon 2.20GHz)\n","Setup complete âœ… (2 CPUs, 12.7 GB RAM, 27.9/107.7 GB disk)\n"]}]},{"cell_type":"code","source":["MODEL = \"yolov8x.pt\""],"metadata":{"id":"H4awyIwh6Cfn","executionInfo":{"status":"ok","timestamp":1702104579977,"user_tz":-330,"elapsed":23,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","model = YOLO(MODEL)\n","model.fuse()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"njeLezRj6Cin","executionInfo":{"status":"ok","timestamp":1702104585972,"user_tz":-330,"elapsed":6013,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}},"outputId":"18fe8ac3-810f-4736-d897-c0cb70bee200"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"hQW_I9eF6Clv","executionInfo":{"status":"ok","timestamp":1702104585977,"user_tz":-330,"elapsed":35,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# dict maping class_id to class_name\n","CLASS_NAMES_DICT = model.model.names\n","\n","# class_ids of interest - car, motorcycle, bus and truck\n","selected_classes = [2, 3, 5, 7]"],"metadata":{"id":"W4_kuikK6CoO","executionInfo":{"status":"ok","timestamp":1702104585978,"user_tz":-330,"elapsed":30,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!pip install supervision\n","\n","from IPython import display\n","display.clear_output()\n","\n","import supervision as sv\n","print(\"supervision.__version__:\", sv.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4y8T1myI6Cro","executionInfo":{"status":"ok","timestamp":1702104595540,"user_tz":-330,"elapsed":9590,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}},"outputId":"4c83e7c0-0e15-4b26-d427-130a34dfb392"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["supervision.__version__: 0.17.1\n"]}]},{"cell_type":"code","source":["import supervision as sv\n","import numpy as np"],"metadata":{"id":"qVa9B33K6Cty","executionInfo":{"status":"ok","timestamp":1702104595542,"user_tz":-330,"elapsed":36,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# create BYTETracker instance\n","byte_tracker = sv.ByteTrack(track_thresh=0.25, track_buffer=30, match_thresh=0.8, frame_rate=30)"],"metadata":{"id":"Z7gJxwPZ6CyA","executionInfo":{"status":"ok","timestamp":1702104595543,"user_tz":-330,"elapsed":34,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import cv2\n","from google.colab.patches import cv2_imshow\n","from math import sqrt"],"metadata":{"id":"xiK3ELDm-Oqf","executionInfo":{"status":"ok","timestamp":1702104595543,"user_tz":-330,"elapsed":33,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zXS6vI-s_unX","executionInfo":{"status":"ok","timestamp":1702104595545,"user_tz":-330,"elapsed":34,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["%cd {HOME}\n","!git clone https://github.com/ifzhang/ByteTrack.git\n","%cd {HOME}/ByteTrack\n","\n","\n","!sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n","\n","!pip3 install -q -r requirements.txt\n","!python3 setup.py -q develop\n","!pip install -q cython_bbox\n","!pip install -q onemetric\n","\n","!pip install -q loguru lap thop\n","\n","from IPython import display\n","display.clear_output()\n","\n","\n","import sys\n","sys.path.append(f\"{HOME}/ByteTrack\")\n","\n","\n","import yolox\n","print(\"yolox.__version__:\", yolox.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r-m5oxUL_uqO","executionInfo":{"status":"ok","timestamp":1702104693291,"user_tz":-330,"elapsed":97779,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}},"outputId":"8a9c00b3-c397-4f82-bca8-f6022fe4c8b8"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["yolox.__version__: 0.1.0\n"]}]},{"cell_type":"code","source":["from yolox.tracker.byte_tracker import BYTETracker, STrack\n","from onemetric.cv.utils.iou import box_iou_batch\n","from dataclasses import dataclass"],"metadata":{"id":"NxPB8-I3_uxx","executionInfo":{"status":"ok","timestamp":1702104693292,"user_tz":-330,"elapsed":23,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class BYTETrackerArgs:\n","    def __init__(self, track_thresh, track_buffer, mot20, match_thresh, \\\n","                aspect_ratio_thresh, min_box_area):\n","        self.track_thresh        = track_thresh\n","        self.track_buffer        = track_buffer\n","        self.mot20               = mot20\n","        self.match_thresh        = match_thresh\n","        self.aspect_ratio_thresh = aspect_ratio_thresh\n","        self.min_box_area        = min_box_area\n","\n","\n","def countVehicles(video_path, output_file_name, vertical, roi_xxyy=(0,0,0,0)):\n","    #frames_list = []\n","\n","    assert type(video_path)       == str, \"video_path argument should be string\"\n","    assert type(output_file_name) == str, \"output_file_name argument should be string\"\n","    assert type(vertical)         == bool, \"vertical argument should be boolean\"\n","\n","    args = BYTETrackerArgs(track_thresh = 0.25,\n","                           track_buffer = 30,\n","                           mot20 = False,\n","                           match_thresh = 0.8,\n","                           aspect_ratio_thresh = 3.0,\n","                           min_box_area = 1.0)\n","\n","    obj_tracker = BYTETracker(args)\n","\n","    vid     = cv2.VideoCapture(video_path)\n","    counter = 0\n","    fps = vid.get(cv2.CAP_PROP_FPS)\n","    writer= cv2.VideoWriter(str(output_file_name), cv2.VideoWriter_fourcc(*'DIVX'), fps, (1067,600))\n","\n","    ids                  = []\n","    already_tested_ids   = []\n","    too_close_tracks_ids = []\n","\n","    maximum_n = 0 # to keep track of maximum height of counted vehicles in each row, so we can go to next row\n","                  # when we reached end of the frame\n","    while True:\n","        ret, frame    = vid.read()\n","\n","        if ret:\n","            frame         = cv2.resize(frame, (1067,600)) # maintaining 16:9 ratio\n","            height, width = frame.shape[:2]\n","\n","            # if cars are moving horizontally and user wants to use the default ROI parameters\n","            if (not vertical) and roi_xxyy == (0,0,0,0):\n","                x_starting_point = round(width/5)\n","                x_ending_point   = round(4*width/5)\n","                y_starting_point = round(height/2) + 50\n","                y_ending_point   = round(height/2) + 250\n","\n","            # if cars are moving vertically and user wants to use the default ROI parameters\n","            elif (vertical) and roi_xxyy == (0,0,0,0):\n","                x_starting_point = 0                #round(width/3)\n","                x_ending_point   = round(3*width/4)\n","                y_starting_point = round(height/2)\n","                y_ending_point   = height           #round(height/2) + 100\n","\n","            # if user wants to use the his own ROI parameters\n","            else:\n","                a, b, c, d = roi_xxyy\n","                assert type(a) == int, \"roi_xxyy argument should be a list or tuple of integers\"\n","                assert type(b) == int, \"roi_xxyy argument should be a list or tuple of integers\"\n","                assert type(c) == int, \"roi_xxyy argument should be a list or tuple of integers\"\n","                assert type(d) == int, \"roi_xxyy argument should be a list or tuple of integers\"\n","\n","                x_starting_point = a\n","                x_ending_point   = b\n","                y_starting_point = c\n","                y_ending_point   = d\n","\n","\n","\n","            if not vertical:\n","                areaLine1   = x_starting_point + int((x_ending_point - x_starting_point)/2) - 15\n","                areaLine2   = x_starting_point + int((x_ending_point - x_starting_point)/2) + 15\n","            else:\n","                areaLine1   = y_ending_point - 150\n","                areaLine2   = y_ending_point - 100\n","\n","            # apply adaptive histogram equalization (AHE) in order to increase the contrast in our region of interest.\n","            clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8,8))\n","\n","            R, G, B = cv2.split(frame[y_starting_point:y_ending_point, x_starting_point:x_ending_point]) # we don't need to\n","                                                                                                         # apply AHE\n","                                                                                                         # to the whole\n","                                                                                                         # frame\n","\n","            cl1 = clahe.apply(R)\n","            cl2 = clahe.apply(G)\n","            cl3 = clahe.apply(B)\n","\n","            orig_frame       = frame.copy() # we take a copy of our original frame before loosing it.\n","            frame            = cv2.merge((cl1, cl2, cl3))\n","            frame_h, frame_w = frame.shape[:2]\n","            frame_size       = np.array([frame_h, frame_w])\n","            orig_frame[y_starting_point:y_ending_point, x_starting_point:x_ending_point] = frame # we replace the region of\n","                                                                                                 # interest with\n","                                                                                                 # the enhanced version of\n","                                                                                                 # it.\n","\n","            res    = model.predict(frame) # we do the prediction only on the ROI. and not the whole frame.\n","            print(f\"This is the prediction  :{res}\")\n","            xyxys  = []\n","            confss = []\n","            oids   = []\n","\n","            for result in res:\n","                for box, r in zip(result.boxes, result.boxes.data):\n","                    x, y, w, h = box.xywh[0]\n","                    # we add x_starting_point and y_starting_point to x and y coordinate because we shrinked the frame earlier\n","                    x1, y1, x2, y2 = int(x) + x_starting_point - int(w/2), int(y) + y_starting_point - int(h/2),\\\n","                                    int(x) + x_starting_point + int(w/2), int(y) + y_starting_point + int(h/2)\n","\n","                    # if class of the detected object is not vehicle then discard it\n","                    if r[-1] > 0 and r[-1] < 8:\n","                        xyxys.append([x1, y1, x2, y2, r[-2]]) # xyxy and score\n","                    confss.append(r[-2])\n","                    oids.append(r[-1]) # class of the detected object\n","\n","\n","            if len(xyxys) > 0:\n","                tracks = obj_tracker.update(np.array(xyxys), frame_size, frame_size)\n","            else:\n","                tracks = np.array([])\n","\n","\n","            if not vertical:\n","                # areaLine1\n","                cv2.line(orig_frame, (areaLine1, y_starting_point), (areaLine1,y_ending_point), (0,0,255), 2)\n","                # areaLine2\n","                cv2.line(orig_frame, (areaLine2, y_starting_point), (areaLine2,y_ending_point), (0,0,255), 2)\n","            else:\n","                # areaLine1\n","                cv2.line(orig_frame, (x_starting_point, areaLine1), (x_ending_point,areaLine1), (0,0,255), 2)\n","                # areaLine2\n","                cv2.line(orig_frame, (x_starting_point, areaLine2), (x_ending_point,areaLine2), (0,0,255), 2)\n","\n","            for track in tracks:\n","\n","                cv2.putText(orig_frame, str(track.track_id), (int(track.tlbr[0]), int(track.tlbr[1])),cv2.FONT_HERSHEY_SIMPLEX,0.5, [255, 255, 0], thickness=1, lineType=cv2.LINE_AA)\n","                if not vertical:\n","                    conditions = ((track.tlbr[0] > areaLine1 and track.tlbr[0]< areaLine2) and # upper left corner of the bbox should be in the area\n","                                    track.track_id not in ids and\n","                                    track.score > 0.6)\n","                else:\n","                    conditions = ((track.tlbr[1] > areaLine1 and track.tlbr[1]< areaLine2) and # upper left corner of the bbox should be in the area\n","                                    track.track_id not in ids and\n","                                    track.score > 0.6)\n","\n","                if (conditions):\n","\n","                    cv2.putText(orig_frame, str(track.track_id), (int(track.tlbr[0]), int(track.tlbr[1])),cv2.FONT_HERSHEY_SIMPLEX,0.8, [0, 255, 0], thickness=2, lineType=cv2.LINE_AA)\n","                    ids.append(track.track_id)\n","\n","\n","            # Showing the counter on top left side of the frame\n","            counter = len(ids)\n","            cv2.putText(orig_frame, \"Count: \" + str(counter), (50,50), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 1, color=(255, 0, 0))\n","\n","            n = 20   # starting row for displaying the counted vehicle image in the original frame\n","            m = 250  # starting column for displaying the counted vehicle image in the original frame\n","\n","            for track in tracks:\n","                if (track.track_id in ids):\n","                    cv2.rectangle(orig_frame, (int(track.tlbr[0]),int(track.tlbr[1])), (int(track.tlbr[2]),int(track.tlbr[3])), (0,255,0), 2)\n","                    cv2.rectangle(orig_frame, (m, n), (m+int(track.tlwh[2]), n+int(track.tlwh[3])), (0,255,0), 2)\n","                    try:\n","                        orig_frame[n:n+int(track.tlwh[3]), m:m+int(track.tlwh[2])] = \\\n","                            orig_frame[int(track.tlwh[1]):int(track.tlwh[1])+int(track.tlwh[3]), int(track.tlwh[0]):int(track.tlwh[0])+int(track.tlwh[2])]\n","                        m += int(track.tlwh[2])+5\n","                    except:\n","                        print(\"Error!\")\n","\n","            # drawing our RoI (Region of Interest)\n","            cv2.rectangle(orig_frame, (x_starting_point, y_starting_point), (x_ending_point,y_ending_point), (255,255,0), 1)\n","\n","            writer.write(orig_frame)\n","            cv2_imshow(orig_frame) #('frame',)\n","\n","            #frames_list.append(orig_frame)\n","            # press esc for quitting the video\n","            if cv2.waitKey(1) & 0xFF == 27:\n","                break\n","        else:\n","            break\n","\n","    vid.release()\n","    writer.release()\n","    #cv2.destroyAllWindows()\n","    #return frames_list\n"],"metadata":{"id":"LNETFY3s9VIe","executionInfo":{"status":"ok","timestamp":1702104693891,"user_tz":-330,"elapsed":616,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wDMw-3dc7xKn","executionInfo":{"status":"ok","timestamp":1702104697311,"user_tz":-330,"elapsed":3430,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}},"outputId":"a5041d9d-57b8-4407-b614-6786022c0c4a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# options for videos:\n","# vehicles moving vertically  (vertical: True): los_angeles.mp4, highway.mp4\n","# vehicles moving horzintally (vertical: False): driving1.mp4\n","countVehicles( '/content/drive/MyDrive/Semester 3/CV/Project/CV course project/los_angeles.mp4',\n","              '/content/drive/MyDrive/Semester 3/CV/Project/CV course project/driving1.mp4', True)"],"metadata":{"id":"Hu5BlQLC9VLH","executionInfo":{"status":"ok","timestamp":1702104730587,"user_tz":-330,"elapsed":6,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_p9PrY_kO2eg","executionInfo":{"status":"ok","timestamp":1702104697313,"user_tz":-330,"elapsed":12,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3901MIV-Q85A","executionInfo":{"status":"ok","timestamp":1702104697923,"user_tz":-330,"elapsed":620,"user":{"displayName":"YUGANDHAR RAJENDRA DHANDE","userId":"10111833824132464753"}}},"execution_count":15,"outputs":[]}]}